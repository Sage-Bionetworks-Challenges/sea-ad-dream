---
title: "Compare Methods with AI Agent Submissions - Task1"
author: "Sage CNB Team"
date: "2025-11-17"
output:
  html_document: default
---

## Introduction & Goal üéØ

This notebook compares _all_ final submissions submitted to the
[SEA-AD DREAM Challenge](https://www.synapse.org/sea_ad_dream), including those
submitted to the Agent tracks. A primary goal of this analysis is to assess the
performance of AI agent submissions relative to the human submissions.

The comparison will perform the same methodology used in the `determine-top-performers` notebooks.


```{r echo=FALSE, message=FALSE, warning=FALSE}
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(knitr))
suppressPackageStartupMessages(library(synapser))

# Login to Synapse.
syn$login(silent=TRUE)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
# --- Import scoring functions ---
reticulate::source_python("../evaluation/dream_evaluation.py")

# --- Helper functions ---
get_name <- function(id) {
  name <- tryCatch({
    syn$getUserProfile(id)$userName
  }, error = function(err) {
    syn$getTeam(id)$name
  })
  name
}

computeBayesFactor <- function(bootstrapMetricMatrix,
                               refPredIndex,
                               invertBayes) {
  M <- as.data.frame(bootstrapMetricMatrix - bootstrapMetricMatrix[,refPredIndex])
  K <- apply(M ,2, function(x) {
    k <- sum(x >= 0)/sum(x < 0)
    
    # Logic handles whether reference column is the best set of predictions.
    if(sum(x >= 0) > sum(x < 0)){
      return(k)
    }else{
      return(1/k)
    }
  })
  K[refPredIndex] <- 0
  if(invertBayes == T){K <- 1/K}
  return(K)
}
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
## Groundtruth file
truth <- readr::read_csv(syn$get("syn70199164")$path) %>%
  janitor::clean_names() %>%  # Clean up colnames
  select(-x1)  # Remove `x1` column from df
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
## Prediction files
task1 <- syn$tableQuery(
  "SELECT
    evaluationid,
    id,
    submitterid,
    ADNC_QWK,
    prediction_fileid
  FROM
    syn68896134 
  WHERE
    evaluationid IN (9617459, 9617461)
    AND status = 'ACCEPTED'
    AND submission_status = 'SCORED'
    AND submitterid <> 3393723
  ORDER BY
    ADNC_QWK DESC"
)$asDataFrame() %>%
  
  # Add a note on whether the submission is for the Agent track
  mutate(
    notes = if_else(evaluationid == "9617461", "Agent track submission", "")
  ) %>%
  select(-evaluationid)
  

# Replace IDs with usernames/team names.
task1$submitterid <- as.character(task1$submitterid)
team_names <- sapply(task1$submitterid, function(sub) {
  get_name(sub)
})
task1$submitterid <- team_names

# Drop row.names for easier table reading.
row.names(task1) <- NULL
kable(
  task1 %>% select(-prediction_fileid),
  caption="Task 1 Final Round Submissions (Both Human and Agent Tracks)"
)
```


## Bootstrapping Procedure üìä

```{r echo=FALSE, message=FALSE, warning=FALSE}
pred_filenames <- lapply(task1$prediction_fileid, function(id) {
  syn$get(id)$path
})
names(pred_filenames) <- team_names

submissions <- lapply(names(pred_filenames), function(team) {
  
  # Read in prediction files
  readr::read_csv(pred_filenames[[team]], show_col_types = FALSE) %>%
  
  # Clean up column names (removes spaces, special chars)
  janitor::clean_names() %>% 
    
  # Only consider the Donor ID and ADNC from the prediction file
  select("donor_id", "predicted_adnc") %>%
    
  # Replace "predicted_ADNC" with the team name for easier identification after
  # merging with the groundtruth
  rename(!!team := predicted_adnc) 
}) %>% 
  
  # Merge the prediction columns together
  purrr::reduce(left_join, by="donor_id") %>%
  
  # Merge in the groundtruth target values
  left_join(truth %>% select("donor_id", "adnc"), by="donor_id") %>%
  
  # Rename "ADNC" column from groundtruth to "truth"
  rename(truth = adnc)

kable(
  head(submissions),
  caption="Preview of Model Predictions and Corresponding Groundtruth Values"
)
```

Double-check that the bootstrapping logic is correct before running the
resource-intensive bootstrapping ($N=10,000$)./

```{r echo=FALSE, message=FALSE, warning=FALSE}
bs.check <- sapply(names(pred_filenames), function(team) {
  apply(matrix(1:nrow(truth), nrow(truth), 1), 2, function(ind) {
    cohen_kappa_score(
      submissions$truth[ind],
      submissions[[team]][ind],
      weights="quadratic"
    )
  })
})

kable(
  bs.check %>%
    as_tibble(rownames = "submitterid") %>%
    left_join(task1, by = "submitterid") %>%
    mutate(
      scores_match = dplyr::near(value, ADNC_QWK)
    ) %>%
    select(
      submitterid,
      bf_calculated_score = value,
      original_score = ADNC_QWK,
      scores_match
    ),
  caption='Comparison of "Bootstrapped" Scores (Prior to Resampling) and Original Scores'
)
```

Since the scores match with the original scores, we can now proceed with the 
official bootstrapping.

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Set seed for reproducible results (since we're doing a random sample)
set.seed(202511)

# Run bootstrapping.
N <- 10000
bs_indices <- matrix(1:nrow(truth), nrow(truth), N) %>%
  apply(2, sample, replace = TRUE)

bs <- sapply(names(pred_filenames), function(team) {
  apply(bs_indices, 2, function(ind) {
    cohen_kappa_score(
      submissions$truth[ind],
      submissions[[team]][ind],
      weights="quadratic"
    )
  })
})
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
##
## Analysis for running on a subset of the data.
## Saving here in case we need it.
##
# sample_percentage <- 0.1
# number_of_samples <- round(nrow(truth) * sample_percentage)
# bs <- sapply(names(pred_filenames), function(team) {
#   apply(bs_indices[1:number_of_samples,], 2, function(ind) {
#     cohen_kappa_score(submissions$truth[ind], submissions[[team]][ind], weights="quadratic")
#   })
# })
```

## Bayes Factor Calculation üìà

```{r echo=FALSE, message=FALSE, warning=FALSE}
bf <- computeBayesFactor(bs, refPredIndex = 1, invertBayes = FALSE) %>%
  as_tibble(rownames = "submission") %>%
  rename(bayes = value) %>%
  mutate(
    bayes = if_else(submission == "longminh1911", 0, bayes)
  )
kable(
  bf %>%
  left_join(
    task1 %>% select(submitterid, notes),
    by = c("submission" = "submitterid")
  )
)
```

## Results & Conclusion üèÜ

```{r echo=FALSE, message=FALSE, warnings=FALSE}

# --- PLOT 1: Bootstrapped score distribution (boxplot) ---
plot <- bs %>%
  as_tibble() %>%
  tidyr::gather(submission, bs_score) %>%
  left_join(bf) %>%
  mutate(bayes_category=case_when(
    bayes == 0 ~ "Top Performers",
    bayes <= 3 ~ "Bayes Factor ‚â§3",
    bayes > 3 ~ "Bayes Factor >3")) %>%
  ggplot(aes(
    x = forcats::fct_reorder(submission, bs_score, .fun = mean),
    y = bs_score,
    color = bayes_category
  )) +
  geom_boxplot(lwd = 1.2, median.linewidth = 1) +
  theme_bw() +
  scale_color_manual(values = c(
    "Top Performers" = "#FFBF00", 
    'Bayes Factor ‚â§3' = '#219EE6', 
    "Bayes Factor >3" = "#B6B5B3"),
    name = NULL) +
  coord_flip() +
  labs(x="Team", y="Bootstrapped ADNC_QWK\n(num_iterations=10,000)") +
  theme(
    axis.text.y.left = element_text(size = 12),
    axis.text.x.bottom = element_text(size = 12),
    text = element_text(size = 10),
    legend.text = element_text(size = 10),
    legend.position = c(0.2, 0.9),
    legend.background = element_rect(linetype = "solid", color = "black"))

# --- PLOT 2: BF comparison (bar plot) ---
plot.bf.top <- bf %>% 
  mutate(bayes_category=case_when(
    bayes == 0 ~ "Top Performers",
    bayes <= 3 ~ "Bayes Factor ‚â§3",
    bayes > 3 ~ "Bayes Factor >3")) %>% 
  ggplot(aes(submission, bayes, fill=bayes_category)) + 
  geom_bar(stat='identity') + 
  coord_flip(ylim = c(0, 20)) +
  geom_hline(yintercept = 3, linetype = 2, lwd = 1.2, color="#7d2929") +
  theme_classic() + 
  scale_x_discrete(limits=names(sort(colMeans(bs)))) + 
  scale_fill_manual(values = c(
    "Top Performers" = "#FFBF00", 
    'Bayes Factor ‚â§3' = '#219EE6', 
    "Bayes Factor >3" = "#B6B5B3")) +
  theme(legend.position = "none") +
  theme(
    text = element_text(size = 10),
    axis.text.x.bottom = element_text(size = 12),
    axis.title.y=element_blank(), 
    axis.text.y=element_blank()) + 
  labs(y="Bayes Factor\n(tie cut-off=3)")


ggsave(
  file="figures/sea-ad-dream_all-methods_task1.svg",
  plot=gridExtra::grid.arrange(plot, plot.bf.top, ncol = 2, widths = c(3, 1)),
  width = 10,
  height = 8,
  units = "in"
)
```

Similar to the official evaluation, this analysis confirms that team gisl7 is
a top-performer, as well as longminh1911 who made a submission to the AGENT track.

